#!/usr/bin/env python3
"""
Code Generator - Autonomous Development
======================================

Generates intelligent, context-aware code using Cursor agents.
Extracted from the main autonomous_development.py file to follow SRP.
"""

import logging
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

from src.utils.stability_improvements import stability_manager, safe_import


@dataclass
class CodeImprovement:
    """Code improvement suggestion"""
    
    file_path: str
    line_number: int
    current_code: str
    suggested_improvement: str
    improvement_type: str  # 'bug_fix', 'optimization', 'documentation', 'testing'
    confidence: float


@dataclass
class CursorAgentPrompt:
    """Intelligent prompt generated by Cursor agents"""
    
    agent_type: str  # 'code_reviewer', 'documentation_expert', 'testing_specialist', 'performance_analyst'
    context: str  # Current development context
    intelligent_prompt: str  # AI-generated, context-aware prompt
    expected_outcome: str  # What we expect to achieve
    confidence: float  # How confident the agent is in this approach


class CodeGenerator:
    """
    Generates intelligent, context-aware code using Cursor agents.
    
    Responsibilities:
    - Intelligent prompt generation
    - Context analysis and understanding
    - Agent specialization management
    - Code improvement suggestions
    - Confidence scoring
    """
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.CodeGenerator")
        
        # Cursor agent specializations
        self.agent_specializations = {
            "code_reviewer": {
                "expertise": "Advanced code analysis, best practices, architectural patterns",
                "prompt_template": "As a senior code reviewer, analyze this {context} and suggest specific improvements for {improvement_type}. Focus on {focus_area}.",
                "focus_areas": [
                    "code quality",
                    "maintainability",
                    "performance",
                    "security",
                    "readability",
                ],
            },
            "documentation_expert": {
                "expertise": "Technical writing, API documentation, code clarity",
                "prompt_template": "As a documentation specialist, help improve the documentation for this {context}. Identify what's missing and suggest specific enhancements for {improvement_type}.",
                "focus_areas": [
                    "clarity",
                    "completeness",
                    "examples",
                    "structure",
                    "accessibility",
                ],
            },
            "testing_specialist": {
                "expertise": "Test strategy, coverage analysis, edge case identification",
                "prompt_template": "As a testing expert, analyze this {context} and recommend comprehensive testing strategies. What specific tests should be added for {improvement_type}?",
                "focus_areas": [
                    "unit tests",
                    "integration tests",
                    "edge cases",
                    "performance tests",
                    "security tests",
                ],
            },
            "performance_analyst": {
                "expertise": "Performance optimization, bottleneck identification, efficiency improvements",
                "prompt_template": "As a performance optimization specialist, examine this {context} and identify specific performance improvements for {improvement_type}. What optimizations would you recommend?",
                "focus_areas": [
                    "execution speed",
                    "memory usage",
                    "scalability",
                    "resource efficiency",
                    "algorithm optimization",
                ],
            },
            "security_expert": {
                "expertise": "Security analysis, vulnerability assessment, secure coding practices",
                "prompt_template": "As a security expert, review this {context} for potential security concerns related to {improvement_type}. What specific security improvements should be implemented?",
                "focus_areas": [
                    "input validation",
                    "authentication",
                    "authorization",
                    "data protection",
                    "secure communication",
                ],
            },
        }
        
        # Stability management
        self.stability_manager = stability_manager
        
    def generate_intelligent_prompt(self, improvement: CodeImprovement, 
                                  context: Dict[str, Any]) -> CursorAgentPrompt:
        """Generate an intelligent, context-aware prompt using appropriate Cursor agent"""
        
        try:
            # Select the most appropriate agent based on improvement type
            agent_type = self._select_agent_for_improvement(improvement)
            agent_info = self.agent_specializations[agent_type]
            
            # Analyze context to create intelligent prompt
            context_analysis = self._analyze_context(context)
            focus_area = self._select_focus_area(improvement, agent_info)
            
            # Generate intelligent prompt using agent expertise
            intelligent_prompt = self._create_intelligent_prompt(
                agent_info, improvement, context_analysis, focus_area
            )
            
            # Calculate confidence based on context analysis
            confidence = self._calculate_confidence(
                improvement, context_analysis, agent_type
            )
            
            return CursorAgentPrompt(
                agent_type=agent_type,
                context=context_analysis["summary"],
                intelligent_prompt=intelligent_prompt,
                expected_outcome=self._define_expected_outcome(improvement, agent_type),
                confidence=confidence,
            )
            
        except Exception as e:
            self.logger.error(f"Failed to generate intelligent prompt: {e}")
            return None
            
    def _select_agent_for_improvement(self, improvement: CodeImprovement) -> str:
        """Select the most appropriate Cursor agent for the improvement type"""
        agent_mapping = {
            "code_review": "code_reviewer",
            "documentation": "documentation_expert",
            "testing": "testing_specialist",
            "optimization": "performance_analyst",
            "security": "security_expert",
            "bug_fix": "code_reviewer",
        }
        
        return agent_mapping.get(improvement.improvement_type, "code_reviewer")
        
    def _analyze_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze development context to understand current state"""
        try:
            analysis = {
                "file_type": context.get("file_type", "unknown"),
                "language": context.get("language", "python"),
                "complexity": context.get("complexity", "medium"),
                "current_issues": context.get("current_issues", []),
                "recent_changes": context.get("recent_changes", []),
                "summary": self._generate_context_summary(context),
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"Failed to analyze context: {e}")
            return {"summary": "Context analysis failed"}
            
    def _generate_context_summary(self, context: Dict[str, Any]) -> str:
        """Generate a human-readable summary of the development context"""
        try:
            file_type = context.get("file_type", "unknown")
            language = context.get("language", "python")
            complexity = context.get("complexity", "medium")
            issues = context.get("current_issues", [])
            changes = context.get("recent_changes", [])
            
            summary_parts = [
                f"Working with {file_type} file in {language}",
                f"Complexity level: {complexity}"
            ]
            
            if issues:
                summary_parts.append(f"Current issues: {', '.join(issues[:3])}")
                
            if changes:
                summary_parts.append(f"Recent changes: {', '.join(changes[:3])}")
                
            return ". ".join(summary_parts) + "."
            
        except Exception as e:
            self.logger.error(f"Failed to generate context summary: {e}")
            return "Context summary generation failed"
            
    def _select_focus_area(self, improvement: CodeImprovement, 
                          agent_info: Dict[str, Any]) -> str:
        """Select the most appropriate focus area for the improvement"""
        try:
            focus_areas = agent_info.get("focus_areas", [])
            if not focus_areas:
                return "general improvement"
                
            # Simple heuristic: select based on improvement type
            improvement_type = improvement.improvement_type.lower()
            
            if "bug" in improvement_type or "fix" in improvement_type:
                return "code quality"
            elif "performance" in improvement_type or "optimization" in improvement_type:
                return "performance"
            elif "security" in improvement_type:
                return "security"
            elif "test" in improvement_type:
                return "testing"
            elif "doc" in improvement_type:
                return "documentation"
            else:
                return focus_areas[0]  # Default to first focus area
                
        except Exception as e:
            self.logger.error(f"Failed to select focus area: {e}")
            return "general improvement"
            
    def _create_intelligent_prompt(self, agent_info: Dict[str, Any], 
                                 improvement: CodeImprovement,
                                 context_analysis: Dict[str, Any],
                                 focus_area: str) -> str:
        """Create an intelligent prompt using agent expertise and context"""
        try:
            template = agent_info.get("prompt_template", "")
            
            # Fill in template variables
            prompt = template.format(
                context=context_analysis["summary"],
                improvement_type=improvement.improvement_type,
                focus_area=focus_area
            )
            
            # Add specific improvement details
            prompt += f"\n\nSpecific improvement needed: {improvement.suggested_improvement}"
            prompt += f"\nFile: {improvement.file_path}, Line: {improvement.line_number}"
            
            return prompt
            
        except Exception as e:
            self.logger.error(f"Failed to create intelligent prompt: {e}")
            return f"Please help improve the code in {improvement.file_path} at line {improvement.line_number}."
            
    def _calculate_confidence(self, improvement: CodeImprovement,
                            context_analysis: Dict[str, Any],
                            agent_type: str) -> float:
        """Calculate confidence level for the generated prompt"""
        try:
            base_confidence = improvement.confidence
            
            # Adjust based on context quality
            context_quality = 1.0
            if context_analysis.get("file_type") != "unknown":
                context_quality += 0.1
            if context_analysis.get("language") == "python":
                context_quality += 0.1
            if context_analysis.get("current_issues"):
                context_quality += 0.1
                
            # Adjust based on agent specialization match
            agent_match = 1.0
            if agent_type in self.agent_specializations:
                agent_match += 0.1
                
            # Calculate final confidence
            final_confidence = base_confidence * context_quality * agent_match
            
            # Ensure confidence is within bounds
            return max(0.0, min(1.0, final_confidence))
            
        except Exception as e:
            self.logger.error(f"Failed to calculate confidence: {e}")
            return 0.5  # Default confidence
            
    def _define_expected_outcome(self, improvement: CodeImprovement, 
                                agent_type: str) -> str:
        """Define the expected outcome of the improvement"""
        try:
            outcomes = {
                "code_reviewer": "Improved code quality and maintainability",
                "documentation_expert": "Enhanced documentation clarity and completeness",
                "testing_specialist": "Comprehensive test coverage and edge case handling",
                "performance_analyst": "Optimized performance and resource efficiency",
                "security_expert": "Enhanced security and vulnerability protection"
            }
            
            return outcomes.get(agent_type, "Improved code quality and functionality")
            
        except Exception as e:
            self.logger.error(f"Failed to define expected outcome: {e}")
            return "Improved code quality and functionality"
            
    def get_agent_specializations(self) -> Dict[str, Dict[str, Any]]:
        """Get available agent specializations"""
        return self.agent_specializations.copy()
        
    def add_agent_specialization(self, agent_type: str, specialization: Dict[str, Any]) -> bool:
        """Add a new agent specialization"""
        try:
            if agent_type in self.agent_specializations:
                self.logger.warning(f"Agent specialization {agent_type} already exists")
                return False
                
            self.agent_specializations[agent_type] = specialization
            self.logger.info(f"Added agent specialization: {agent_type}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to add agent specialization {agent_type}: {e}")
            return False
            
    def analyze_code_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """Analyze a code file for improvements"""
        try:
            # This is a simplified analysis
            # In production, you'd want more sophisticated code analysis
            return {
                'file_path': file_path,
                'issues': [],
                'metrics': {
                    'documentation_coverage': 75.0,
                    'cyclomatic_complexity': 5,
                    'maintainability_index': 85
                }
            }
        except Exception as e:
            self.logger.error(f"Failed to analyze code file {file_path}: {e}")
            return None
            
    def generate_code_report(self, file_path: str) -> str:
        """Generate a code report for a file"""
        try:
            analysis = self.analyze_code_file(file_path)
            if analysis:
                return f"Code analysis report for {file_path}: {analysis['metrics']}"
            return f"No analysis available for {file_path}"
        except Exception as e:
            self.logger.error(f"Failed to generate code report for {file_path}: {e}")
            return f"Error generating report for {file_path}: {e}"
            
    def analyze_code_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """Analyze a code file for improvements"""
        try:
            # This is a simplified analysis
            # In production, you'd want more sophisticated code analysis
            return {
                'file_path': file_path,
                'issues': [],
                'metrics': {
                    'documentation_coverage': 75.0,
                    'cyclomatic_complexity': 5,
                    'maintainability_index': 85
                }
            }
        except Exception as e:
            self.logger.error(f"Failed to analyze code file {file_path}: {e}")
            return None
            
    def generate_code_report(self, file_path: str) -> str:
        """Generate a code report for a file"""
        try:
            analysis = self.analyze_code_file(file_path)
            if analysis:
                return f"Code analysis report for {file_path}: {analysis['metrics']}"
            return f"No analysis available for {file_path}"
        except Exception as e:
            self.logger.error(f"Failed to generate code report for {file_path}: {e}")
            return f"Error generating report for {file_path}: {e}"
