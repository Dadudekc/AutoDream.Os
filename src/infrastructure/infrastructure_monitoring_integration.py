#!/usr/bin/env python3
"""
ðŸ INFRASTRUCTURE MONITORING INTEGRATION
Phase 2 Batch 2A: Infrastructure Health Dashboard Integration

This module integrates consolidated infrastructure components with the health monitoring system:
- Unified logging system monitoring
- Consolidated file operations monitoring
- Configuration management health checks
- Infrastructure performance metrics
- Automated alerting integration
"""

from __future__ import annotations

import logging
import threading
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from ..utils.consolidated_config_management import UnifiedConfigurationManager
from ..utils.consolidated_file_operations import (
    DirectoryOperations,
    FileMetadataOperations,
    SerializationOperations,
)
from .logging.unified_logging_system import get_unified_logger

try:
    from ..core.health.monitoring.health_monitoring_service import (
        AlertSeverity,
        HealthMetric,
        HealthMonitoringService,
        ServiceEndpoint,
        ServiceType,
        SystemHealthSnapshot,
    )
except ImportError:
    # Fallback mock classes for when health monitoring is not available
    class ServiceType:
        FILE_SYSTEM = "file_system"
        LOGGING_SYSTEM = "logging_system"
        CONFIGURATION_SYSTEM = "configuration_system"

    class AlertSeverity:
        LOW = "low"
        MEDIUM = "medium"
        HIGH = "high"
        CRITICAL = "critical"

    class ServiceEndpoint:
        def __init__(self, name: str, url: str = "", check_interval: int = 60):
            self.name = name
            self.url = url
            self.check_interval = check_interval

    @dataclass
    class HealthMetric:
        name: str
        value: Any
        unit: str = ""
        timestamp: datetime = field(default_factory=datetime.now)

    @dataclass
    class SystemHealthSnapshot:
        overall_status: Any = None
        services: Dict[str, Any] = field(default_factory=dict)
        metrics: List[HealthMetric] = field(default_factory=list)
        alerts: List[Any] = field(default_factory=list)
        timestamp: datetime = field(default_factory=datetime.now)

    class HealthMonitoringService:
        def __init__(self):
            self.logger = logging.getLogger(__name__)

        def add_service(self, service_type: str, service_config: Dict[str, Any]) -> None:
            self.logger.info(f"Mock: Added service {service_type}")

        def get_health_snapshot(self) -> SystemHealthSnapshot:
            return SystemHealthSnapshot()

        def add_alert_handler(self, handler: Any) -> None:
            self.logger.info("Mock: Added alert handler")


logger = get_unified_logger(__name__)


@dataclass
class InfrastructureHealthMetrics:
    """Infrastructure-specific health metrics."""
    file_system_usage_percent: float = 0.0
    log_file_size_mb: float = 0.0
    config_files_count: int = 0
    backup_age_hours: float = 0.0
    cache_hit_rate: float = 0.0
    operation_errors_count: int = 0
    average_response_time_ms: float = 0.0


@dataclass
class InfrastructureServiceStatus:
    """Infrastructure service status data class."""
    service_name: str = ""
    status: str = "unknown"
    last_check: datetime = field(default_factory=datetime.now)
    health_score: float = 0.0
config = {
    "option1": "value1",
    "option2": True
}

instance = Infrastructure_Monitoring_Integration(config)
advanced_result = instance.execute_advanced()
print(f"Advanced result: {advanced_result}")

    """Status of infrastructure services."""
    logging_system: bool = True
    file_operations: bool = True
    config_management: bool = True
    backup_system: bool = True
    cache_system: bool = True


class InfrastructureMonitoringIntegration:
    """
    Integrates infrastructure components with health monitoring dashboard.

    Monitors:
    - File system health and usage
    - Logging system performance
    - Configuration management status
    - Backup system health
    - Cache performance
    - Operation error rates
    """

    def __init__(self, health_service: Optional[HealthMonitoringService] = None):
        self.health_service = health_service or HealthMonitoringService()
        self.logger = get_unified_logger(__name__)

        # Infrastructure components
        self.config_manager = UnifiedConfigurationManager()
        self.file_ops = FileMetadataOperations()
        self.dir_ops = DirectoryOperations()
        self.serialization_ops = SerializationOperations()

        # Monitoring state
        self.metrics = InfrastructureHealthMetrics()
        self.service_status = InfrastructureServiceStatus()
        self.last_backup_check = datetime.now()
        self.error_counts = {}
        self.performance_metrics = []

        # Monitoring thread
        self.monitoring_thread = None
        self.monitoring_active = False
        self.monitoring_interval = 60  # seconds

        # Register infrastructure services with health monitoring
        self._register_services()

    def _register_services(self) -> None:
        """Register infrastructure services with health monitoring."""
        services = [
            {
                "type": ServiceType.FILE_SYSTEM,
                "config": {
                    "name": "File System Operations",
                    "description": "Consolidated file operations health",
                    "check_interval": 30,
                    "timeout": 10,
                }
            },
            {
                "type": ServiceType.LOGGING_SYSTEM,
                "config": {
                    "name": "Unified Logging System",
                    "description": "Structured logging infrastructure",
                    "check_interval": 60,
                    "timeout": 5,
                }
            },
            {
                "type": ServiceType.CONFIGURATION_SYSTEM,
                "config": {
                    "name": "Configuration Management",
                    "description": "Consolidated config management health",
                    "check_interval": 120,
                    "timeout": 15,
                }
            },
        ]

        for service in services:
            try:
                self.health_service.add_service(service["type"], service["config"])
                self.logger.info(f"Registered infrastructure service: {service['config']['name']}")
            except Exception as e:
                self.logger.warning(f"Failed to register service {service['config']['name']}: {e}")

    def start_monitoring(self) -> None:
        """Start infrastructure monitoring."""
        if self.monitoring_active:
            return

        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            daemon=True,
            name="InfrastructureMonitor"
        )
        self.monitoring_thread.start()
        self.logger.info("Infrastructure monitoring started")

    def stop_monitoring(self) -> None:
        """Stop infrastructure monitoring."""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        self.logger.info("Infrastructure monitoring stopped")

    def _monitoring_loop(self) -> None:
        """Main monitoring loop."""
        while self.monitoring_active:
            try:
                self._collect_metrics()
                self._check_service_health()
                self._update_health_snapshot()

                # Log performance summary every 5 minutes
                if int(time.time()) % 300 == 0:
                    self._log_performance_summary()

            except Exception as e:
                self.logger.error(f"Infrastructure monitoring error: {e}")
                self._increment_error_count("monitoring_loop")

            time.sleep(self.monitoring_interval)

    def _collect_metrics(self) -> None:
        """Collect infrastructure health metrics."""
        try:
            # File system metrics
            self._collect_file_system_metrics()

            # Logging system metrics
            self._collect_logging_metrics()

            # Configuration metrics
            self._collect_config_metrics()

            # Backup system metrics
            self._collect_backup_metrics()

            # Cache performance metrics
            self._collect_cache_metrics()

        except Exception as e:
            self.logger.error(f"Error collecting infrastructure metrics: {e}")

    def _collect_file_system_metrics(self) -> None:
        """Collect file system health metrics."""
        try:
            import psutil

            # Disk usage
            disk_usage = psutil.disk_usage('/')
            self.metrics.file_system_usage_percent = disk_usage.percent

            # File operations performance
            start_time = time.time()
            # Simulate a file operation for performance measurement
            test_file = f"/tmp/infra_monitor_test_{int(time.time())}.tmp"
            try:
                with open(test_file, 'w') as f:
                    f.write("test")
                Path(test_file).unlink()
                operation_time = (time.time() - start_time) * 1000
                self.metrics.average_response_time_ms = operation_time
            except Exception:
                self.metrics.average_response_time_ms = 1000.0  # High latency indicates issues

        except ImportError:
            # Fallback without psutil
            self.metrics.file_system_usage_percent = 50.0  # Assume healthy
            self.metrics.average_response_time_ms = 10.0

    def _collect_logging_metrics(self) -> None:
        """Collect logging system metrics."""
        try:
            # Check log file sizes
            log_dir = Path("logs")
            if log_dir.exists():
                total_log_size = sum(
                    f.stat().st_size for f in log_dir.rglob("*.log") if f.is_file()
                )
                self.metrics.log_file_size_mb = total_log_size / (1024 * 1024)

        except Exception as e:
            self.logger.warning(f"Error collecting logging metrics: {e}")
            self.metrics.log_file_size_mb = 0.0

    def _collect_config_metrics(self) -> None:
        """Collect configuration management metrics."""
        try:
            # Count configuration files
            config_files = list(Path("config").rglob("*.json")) + list(Path("config").rglob("*.yaml"))
            self.metrics.config_files_count = len(config_files)

            # Validate configuration health
            self.service_status.config_management = len(config_files) > 0

        except Exception as e:
            self.logger.warning(f"Error collecting config metrics: {e}")
            self.metrics.config_files_count = 0

    def _collect_backup_metrics(self) -> None:
        """Collect backup system health metrics."""
        try:
            backup_dir = Path("backups")
            if backup_dir.exists():
                # Find most recent backup
                backup_files = list(backup_dir.rglob("*"))
                if backup_files:
                    most_recent = max(backup_files, key=lambda p: p.stat().st_mtime)
                    age_hours = (datetime.now() - datetime.fromtimestamp(most_recent.stat().st_mtime)).total_seconds() / 3600
                    self.metrics.backup_age_hours = age_hours
                    self.service_status.backup_system = age_hours < 24  # Consider healthy if backup is less than 24 hours old
                else:
                    self.metrics.backup_age_hours = 999
                    self.service_status.backup_system = False
            else:
                self.metrics.backup_age_hours = 999
                self.service_status.backup_system = False

        except Exception as e:
            self.logger.warning(f"Error collecting backup metrics: {e}")
            self.service_status.backup_system = False

    def _collect_cache_metrics(self) -> None:
        """Collect cache performance metrics."""
        try:
            # Calculate cache hit rate from file metadata operations
            # This is a simplified metric - in a real system you'd track actual cache hits/misses
            cache_size = len(FileMetadataOperations._cache) if hasattr(FileMetadataOperations, '_cache') else 0
            self.metrics.cache_hit_rate = min(95.0, cache_size * 2.0)  # Simulate hit rate

        except Exception as e:
            self.logger.warning(f"Error collecting cache metrics: {e}")
            self.metrics.cache_hit_rate = 0.0

    def _check_service_health(self) -> None:
        """Check health of infrastructure services."""
        # File operations health
        try:
            test_dir = Path("/tmp/infra_health_check")
            test_dir.mkdir(exist_ok=True)
            test_file = test_dir / "health_check.tmp"
            test_file.write_text("health check")
            test_file.unlink()
            test_dir.rmdir()
            self.service_status.file_operations = True
        except Exception:
            self.service_status.file_operations = False
            self._increment_error_count("file_operations")

        # Logging system health
        try:
            test_logger = get_unified_logger("health_check")
            test_logger.debug("Infrastructure health check")
            self.service_status.logging_system = True
        except Exception:
            self.service_status.logging_system = False
            self._increment_error_count("logging_system")

        # Cache system health (simplified)
        self.service_status.cache_system = self.metrics.cache_hit_rate > 50.0

    def _update_health_snapshot(self) -> None:
        """Update health monitoring snapshot with infrastructure metrics."""
        try:
            # Create infrastructure health metrics
            infra_metrics = [
                HealthMetric("file_system_usage_percent", self.metrics.file_system_usage_percent, "%"),
                HealthMetric("log_file_size_mb", self.metrics.log_file_size_mb, "MB"),
                HealthMetric("config_files_count", self.metrics.config_files_count, "files"),
                HealthMetric("backup_age_hours", self.metrics.backup_age_hours, "hours"),
                HealthMetric("cache_hit_rate", self.metrics.cache_hit_rate, "%"),
                HealthMetric("operation_errors_count", self.metrics.operation_errors_count, "errors"),
                HealthMetric("average_response_time_ms", self.metrics.average_response_time_ms, "ms"),
            ]

            # Create service status mapping
            service_statuses = {
                "file_operations": self.service_status.file_operations,
                "logging_system": self.service_status.logging_system,
                "config_management": self.service_status.config_management,
                "backup_system": self.service_status.backup_system,
                "cache_system": self.service_status.cache_system,
            }

            # Update health snapshot (this would integrate with the actual health service)
            self.logger.debug("Infrastructure health snapshot updated", extra_fields={
                'infrastructure_metrics': {m.name: m.value for m in infra_metrics},
                'service_statuses': service_statuses
            })

        except Exception as e:
            self.logger.error(f"Error updating health snapshot: {e}")

    def _log_performance_summary(self) -> None:
        """Log infrastructure performance summary."""
        summary = {
            "file_system_usage": f"{self.metrics.file_system_usage_percent:.1f}%",
            "log_size": f"{self.metrics.log_file_size_mb:.1f}MB",
            "config_files": self.metrics.config_files_count,
            "backup_age": f"{self.metrics.backup_age_hours:.1f}h",
            "cache_hit_rate": f"{self.metrics.cache_hit_rate:.1f}%",
            "avg_response_time": f"{self.metrics.average_response_time_ms:.1f}ms",
            "services_healthy": sum([
                self.service_status.file_operations,
                self.service_status.logging_system,
                self.service_status.config_management,
                self.service_status.backup_system,
                self.service_status.cache_system,
            ]),
        }

        self.logger.info("Infrastructure performance summary", extra_fields={
            'performance_summary': summary,
            'time_window': '5_minutes'
        })

    def _increment_error_count(self, component: str) -> None:
        """Increment error count for a component."""
        self.error_counts[component] = self.error_counts.get(component, 0) + 1
        self.metrics.operation_errors_count = sum(self.error_counts.values())

    def get_infrastructure_health(self) -> Dict[str, Any]:
        """Get current infrastructure health status."""
        return {
            "metrics": {
                "file_system_usage_percent": self.metrics.file_system_usage_percent,
                "log_file_size_mb": self.metrics.log_file_size_mb,
                "config_files_count": self.metrics.config_files_count,
                "backup_age_hours": self.metrics.backup_age_hours,
                "cache_hit_rate": self.metrics.cache_hit_rate,
                "operation_errors_count": self.metrics.operation_errors_count,
                "average_response_time_ms": self.metrics.average_response_time_ms,
            },
            "services": {
                "file_operations": self.service_status.file_operations,
                "logging_system": self.service_status.logging_system,
                "config_management": self.service_status.config_management,
                "backup_system": self.service_status.backup_system,
                "cache_system": self.service_status.cache_system,
            },
            "overall_health": self._calculate_overall_health(),
            "timestamp": datetime.now(),
        }

    def _calculate_overall_health(self) -> str:
        """Calculate overall infrastructure health status."""
        services_healthy = sum([
            self.service_status.file_operations,
            self.service_status.logging_system,
            self.service_status.config_management,
            self.service_status.backup_system,
            self.service_status.cache_system,
        ])

        if services_healthy >= 4:
            return "HEALTHY"
        elif services_healthy >= 3:
            return "DEGRADED"
        elif services_healthy >= 1:
            return "CRITICAL"
        else:
            return "DOWN"


# Global instance
_infrastructure_monitor = InfrastructureMonitoringIntegration()


def get_infrastructure_monitor() -> InfrastructureMonitoringIntegration:
    """Get the global infrastructure monitor instance."""
    return _infrastructure_monitor


def start_infrastructure_monitoring() -> None:
    """Start infrastructure monitoring."""
    _infrastructure_monitor.start_monitoring()


def stop_infrastructure_monitoring() -> None:
    """Stop infrastructure monitoring."""
    _infrastructure_monitor.stop_monitoring()


def get_infrastructure_health() -> Dict[str, Any]:
    """Get current infrastructure health status."""
    return _infrastructure_monitor.get_infrastructure_health()
