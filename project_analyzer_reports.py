#!/usr/bin/env python3
"""
Project Analyzer - Report Generation Module
============================================

Handles report generation and consolidation summary creation.
Part of comprehensive_project_analyzer.py refactoring (623‚Üí<400L).

Author: Agent-2 - Architecture & Design Specialist
Pattern: Facade + Module Splitting (CONSOLIDATION_ARCHITECTURE_PATTERNS.md)
"""

import json
import os
from pathlib import Path
from typing import Any


class ReportGenerator:
    """Generates analysis reports and consolidation summaries."""

    def __init__(
        self, output_dir: Path, analysis_timestamp: str, project_root: Path, chunk_size: int
    ):
        """Initialize report generator."""
        self.output_dir = output_dir
        self.analysis_timestamp = analysis_timestamp
        self.project_root = project_root
        self.chunk_size = chunk_size

    def generate_chunk_reports(
        self,
        directories: list[str],
        core_analyzer,  # CoreAnalyzer instance
        structure: dict[str, Any],
    ) -> None:
        """Generate chunked analysis reports."""
        print("üöÄ Starting comprehensive project analysis with chunked output...")

        # Generate master index
        master_index = {
            "analysis_timestamp": self.analysis_timestamp,
            "project_root": str(self.project_root),
            "chunk_size": self.chunk_size,
            "total_directories": len(directories),
            "project_structure": structure,
            "chunks": [],
        }

        chunk_id = 1
        for directory in directories:
            if not os.path.exists(directory):
                print(f"‚ö†Ô∏è Directory not found: {directory}")
                continue

            # Analyze directory chunk
            chunk_analysis = core_analyzer.analyze_directory_chunk(directory, chunk_id)

            # Save chunk file
            chunk_file = self.output_dir / f"chunk_{chunk_id:03d}_{Path(directory).name}.json"
            with open(chunk_file, "w", encoding="utf-8") as f:
                json.dump(chunk_analysis, f, indent=2)

            # Add to master index
            master_index["chunks"].append(
                {
                    "chunk_id": chunk_id,
                    "directory": directory,
                    "file_path": str(chunk_file),
                    "files_analyzed": chunk_analysis["summary"]["total_files"],
                    "consolidation_opportunities": len(
                        chunk_analysis["consolidation_opportunities"]
                    ),
                }
            )

            print(f"‚úÖ Chunk {chunk_id} saved: {chunk_file}")
            chunk_id += 1

        # Save master index
        master_file = self.output_dir / "master_index.json"
        with open(master_file, "w", encoding="utf-8") as f:
            json.dump(master_index, f, indent=2)

        # Generate consolidation summary
        self.generate_consolidation_summary(master_index)

        print("\nüéâ Analysis complete!")
        print(f"üìÅ Output directory: {self.output_dir}")
        print(f"üìä Total chunks generated: {chunk_id - 1}")
        print(f"üìã Master index: {master_file}")

    def generate_consolidation_summary(self, master_index: dict[str, Any]) -> None:
        """Generate consolidation summary report."""
        total_files = sum(chunk["files_analyzed"] for chunk in master_index["chunks"])
        total_opportunities = sum(
            chunk["consolidation_opportunities"] for chunk in master_index["chunks"]
        )

        summary = f"""# üìä **COMPREHENSIVE PROJECT ANALYSIS - CONSOLIDATION SUMMARY**

**Generated by:** Agent-2 (Architecture & Design Specialist)  
**Analysis Date:** {self.analysis_timestamp}  
**Project Root:** {self.project_root}  
**Analysis Type:** Chunked Comprehensive Analysis  

---

## üìà **ANALYSIS OVERVIEW**

### **Total Analysis:**
- **Chunks Generated:** {len(master_index["chunks"])}
- **Total Files Analyzed:** {total_files}
- **Consolidation Opportunities:** {total_opportunities}
- **Chunk Size:** {self.chunk_size} files per chunk

### **Project Structure:**
- **Total Directories:** {master_index["project_structure"]["total_dirs"]}
- **Total Files:** {master_index["project_structure"]["total_files"]}
- **File Types:** {master_index["project_structure"]["file_types"]}

---

## üéØ **CONSOLIDATION OPPORTUNITIES BY CHUNK**

"""

        for chunk in master_index["chunks"]:
            summary += f"""
### **Chunk {chunk["chunk_id"]:03d}: {Path(chunk["directory"]).name}**
- **Files Analyzed:** {chunk["files_analyzed"]}
- **Consolidation Opportunities:** {chunk["consolidation_opportunities"]}
- **File:** `{chunk["file_path"]}`

"""

        summary += """
---

## üìÅ **GENERATED FILES**

### **Master Index:**
- **`master_index.json`** - Complete project analysis index
- **`consolidation_summary.md`** - This summary report

### **Chunk Files:**
"""

        for chunk in master_index["chunks"]:
            summary += f"- **`{Path(chunk['file_path']).name}`** - {chunk['directory']} analysis\n"

        summary += """
---

## üöÄ **CONSOLIDATION STRATEGY**

### **High-Priority Chunks:**
Focus on chunks with the most consolidation opportunities for maximum impact.

### **Chunk Processing Order:**
1. **Core Modules** - Foundation consolidation
2. **Services** - Business logic optimization  
3. **Web Interface** - Frontend consolidation
4. **Utilities** - Common functionality unification
5. **Configuration** - Settings consolidation

### **Expected Results:**
- **Target File Reduction:** 60-70%
- **Maintenance Improvement:** Significant
- **Development Velocity:** Enhanced
- **Code Quality:** SOLID principles compliance

---

**üêù WE ARE SWARM - Chunked analysis complete and ready for consolidation execution!**
"""

        # Save summary
        summary_file = self.output_dir / "consolidation_summary.md"
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write(summary)

        print(f"üìã Consolidation summary: {summary_file}")
