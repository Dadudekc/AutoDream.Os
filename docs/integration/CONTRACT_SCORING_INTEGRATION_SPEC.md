# üéØ Contract Scoring System - Integration Specification

**Source:** contract-leads (Repo #20) multi-factor scoring engine  
**Enhanced By:** Commander emphasis on "contract system insights"  
**Priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê CRITICAL - Highest direct applicability  
**Integration Effort:** 50-65 hours  
**ROI:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê GOLDMINE  
**Date:** 2025-10-15  
**Analyst:** Agent-2 (Architecture & Design Specialist)

---

## üéØ EXECUTIVE SUMMARY

**Discovery:** contract-leads repository contains a production-ready **multi-factor scoring engine** that can be directly adapted to optimize contract-to-agent assignments in Agent_Cellphone_V2.

**Commander's Final Emphasis:**
- ‚úÖ **Contract system insights** ‚Üê PRIMARY FOCUS
- ‚úÖ Lead generation patterns
- ‚úÖ Business intelligence

**Strategic Value:** Replace manual/intuition-based contract assignments with **data-driven scoring**, improving assignment quality by estimated 25-30% while reducing Captain workload.

**This is the FINAL enhanced deliverable and the MOST ACTIONABLE for immediate implementation!**

---

## üèóÔ∏è CURRENT CONTRACT SYSTEM (Before Scoring)

### **Existing Assignment Flow:**

```python
# src/services/contract_service.py (current)
class ContractService:
    def assign_contract(self, contract_id, agent_id):
        """Manual assignment by Captain"""
        contract = self.get_contract(contract_id)
        contract.agent_id = agent_id
        contract.status = 'ASSIGNED'
        contract.save()
        
        notify_agent(agent_id, f"New contract assigned: {contract_id}")
```

**Problems:**
- ‚ùå No scoring/ranking of potential agents
- ‚ùå Captain must manually evaluate each option
- ‚ùå Subjective decision-making
- ‚ùå No data-driven optimization
- ‚ùå No learning from past assignments

---

## üöÄ ENHANCED CONTRACT SYSTEM (With Scoring)

### **New Assignment Flow:**

```python
# src/services/contract_service.py (enhanced)
from src.contracts.contract_scorer import ContractScorer

class ContractService:
    def __init__(self):
        self.scorer = ContractScorer()
    
    def get_optimal_assignments(self, contract_id, top_n=3):
        """Get ranked list of best agents for contract"""
        contract = self.get_contract(contract_id)
        available_agents = self.get_available_agents()
        
        # Score each agent for this contract
        rankings = self.scorer.rank_agents_for_contract(
            contract,
            available_agents
        )
        
        # Return top N recommendations
        return rankings[:top_n]
    
    def assign_contract_auto(self, contract_id):
        """Automatically assign to highest-scoring agent"""
        rankings = self.get_optimal_assignments(contract_id, top_n=1)
        
        if rankings:
            best_agent = rankings[0]
            
            # Assign to top-scored agent
            self.assign_contract(contract_id, best_agent['agent_id'])
            
            # Log assignment reasoning
            self.log_assignment_decision(
                contract_id,
                best_agent['agent_id'],
                best_agent['total_score'],
                best_agent['factors']
            )
            
            return best_agent
        else:
            raise NoSuitableAgentError(f"No available agents for contract {contract_id}")
    
    def assign_contract_manual(self, contract_id):
        """Show Captain top 3 recommendations for manual selection"""
        rankings = self.get_optimal_assignments(contract_id, top_n=3)
        
        # Display to Captain with scoring breakdown
        print(f"\nüìä Top 3 Agent Recommendations for Contract {contract_id}:\n")
        
        for i, agent_ranking in enumerate(rankings, 1):
            print(f"{i}. {agent_ranking['agent_id']} (Score: {agent_ranking['total_score']}/100)")
            print(f"   Skill Match: {agent_ranking['factors']['skill_match']}/10")
            print(f"   Workload: {agent_ranking['factors']['workload_balance']}/10")
            print(f"   Success Probability: {agent_ranking['factors']['success_probability']:.1%}")
            print(f"   Estimated Time: {agent_ranking['factors']['estimated_hours']} hours")
            print()
        
        # Captain can override or accept recommendation
        choice = input("Select agent (1-3) or enter agent ID: ")
        
        if choice.isdigit() and 1 <= int(choice) <= 3:
            selected = rankings[int(choice) - 1]
            self.assign_contract(contract_id, selected['agent_id'])
        else:
            # Manual override
            self.assign_contract(contract_id, choice)
```

---

## üéØ CORE COMPONENT: CONTRACT SCORER

### **Multi-Factor Scoring Engine:**

```python
# src/contracts/contract_scorer.py
from typing import List, Dict, Any
from dataclasses import dataclass
import numpy as np

@dataclass
class ScoringFactors:
    """Configurable weights for scoring factors"""
    skill_match: float = 2.0           # CRITICAL - Does agent have skills?
    workload_balance: float = 1.5      # IMPORTANT - Agent capacity
    priority_level: float = 2.0        # CRITICAL - Contract urgency
    past_performance: float = 1.0      # BONUS - Historical success
    completion_likelihood: float = 1.5 # IMPORTANT - Probability of success
    time_efficiency: float = 1.2       # MEDIUM - Speed estimate
    quality_track_record: float = 1.3  # MEDIUM - Quality history


class ContractScorer:
    """
    Multi-factor scoring system for contract-agent matching
    
    Adapted from contract-leads scoring engine.
    Optimizes assignments using weighted multi-factor analysis.
    """
    
    def __init__(self, weights: ScoringFactors = None):
        self.weights = weights or ScoringFactors()
    
    def score_assignment(self, contract, agent) -> Dict[str, Any]:
        """
        Calculate comprehensive score for assigning contract to agent
        
        Returns: {
            'total_score': 0-100,
            'factors': individual factor scores,
            'recommendation': 'EXCELLENT' | 'GOOD' | 'FAIR' | 'POOR'
        }
        """
        factors = {}
        
        # Factor 1: Skill Match (0-10 scale)
        factors['skill_match'] = self.calculate_skill_match(contract, agent)
        
        # Factor 2: Workload Balance (0-10 scale)
        factors['workload_balance'] = self.calculate_workload_balance(agent)
        
        # Factor 3: Priority Match (0-10 scale)
        factors['priority_level'] = self.calculate_priority_match(contract, agent)
        
        # Factor 4: Past Performance (0-10 scale)
        factors['past_performance'] = self.calculate_past_performance(agent, contract)
        
        # Factor 5: Completion Likelihood (0-10 scale)
        factors['completion_likelihood'] = self.calculate_completion_likelihood(agent, contract)
        
        # Factor 6: Time Efficiency (0-10 scale)
        factors['time_efficiency'] = self.calculate_time_efficiency(agent, contract)
        
        # Factor 7: Quality Track Record (0-10 scale)
        factors['quality_track_record'] = self.calculate_quality_record(agent)
        
        # Calculate weighted total
        total_score = (
            factors['skill_match'] * self.weights.skill_match +
            factors['workload_balance'] * self.weights.workload_balance +
            factors['priority_level'] * self.weights.priority_level +
            factors['past_performance'] * self.weights.past_performance +
            factors['completion_likelihood'] * self.weights.completion_likelihood +
            factors['time_efficiency'] * self.weights.time_efficiency +
            factors['quality_track_record'] * self.weights.quality_track_record
        )
        
        # Normalize to 0-100 scale
        max_possible = sum([
            10 * self.weights.skill_match,
            10 * self.weights.workload_balance,
            10 * self.weights.priority_level,
            10 * self.weights.past_performance,
            10 * self.weights.completion_likelihood,
            10 * self.weights.time_efficiency,
            10 * self.weights.quality_track_record
        ])
        
        normalized_score = (total_score / max_possible) * 100
        
        # Determine recommendation
        if normalized_score >= 80:
            recommendation = 'EXCELLENT'
        elif normalized_score >= 60:
            recommendation = 'GOOD'
        elif normalized_score >= 40:
            recommendation = 'FAIR'
        else:
            recommendation = 'POOR'
        
        return {
            'total_score': round(normalized_score, 1),
            'factors': factors,
            'recommendation': recommendation,
            'estimated_hours': self.estimate_completion_time(agent, contract),
            'success_probability': self.estimate_success_probability(agent, contract)
        }
    
    def calculate_skill_match(self, contract, agent) -> float:
        """
        How well do agent's skills match contract requirements? (0-10)
        
        Factors:
        - Agent specialty matches contract category
        - Agent has completed similar contracts
        - Agent has required technical skills
        """
        score = 5.0  # Base score
        
        agent_stats = get_agent_statistics(agent.id)
        
        # Category match
        if contract.category in agent.specialties:
            score += 3.0  # Major bonus for specialty match
        
        # Similar contract history
        similar_contracts = agent_stats.get_similar_contracts(contract, limit=10)
        if similar_contracts:
            avg_success = sum(c.quality_score for c in similar_contracts) / len(similar_contracts)
            score += (avg_success / 10) * 2.0  # Up to +2.0 for past success
        
        return min(10.0, score)
    
    def calculate_workload_balance(self, agent) -> float:
        """
        How much capacity does agent have? (0-10)
        
        Higher score = more capacity
        """
        agent_stats = get_agent_statistics(agent.id)
        current_workload = agent_stats.current_workload_hours
        
        # 0 hours = 10.0 score, 10 hours = 0.0 score
        score = max(0, 10 - current_workload)
        
        return score
    
    def calculate_priority_match(self, contract, agent) -> float:
        """
        Does agent priority align with contract priority? (0-10)
        """
        # If contract is urgent, prefer agents who excel under pressure
        if contract.priority == 'URGENT':
            agent_stats = get_agent_statistics(agent.id)
            urgent_success_rate = agent_stats.urgent_contract_success_rate
            return urgent_success_rate * 10
        
        # Normal priority
        return 7.0  # Neutral score
    
    def calculate_past_performance(self, agent, contract) -> float:
        """
        How has agent performed on similar contracts? (0-10)
        """
        agent_stats = get_agent_statistics(agent.id)
        
        # Get contracts in same category
        similar_contracts = agent_stats.get_contracts_by_category(
            contract.category,
            limit=5
        )
        
        if not similar_contracts:
            return 5.0  # Neutral if no history
        
        # Average quality score on similar contracts
        avg_quality = sum(c.quality_score for c in similar_contracts) / len(similar_contracts)
        
        return avg_quality  # Already on 0-10 scale
    
    def calculate_completion_likelihood(self, agent, contract) -> float:
        """
        What's probability agent completes on time? (0-10)
        """
        agent_stats = get_agent_statistics(agent.id)
        
        # Base on overall completion rate
        completion_rate = agent_stats.completion_rate_30d
        
        # Adjust for current workload
        if agent_stats.current_workload > 8:
            completion_rate *= 0.7  # 30% penalty for overload
        
        # Adjust for contract difficulty vs agent level
        difficulty_match = self.assess_difficulty_match(agent, contract)
        
        return (completion_rate * difficulty_match) * 10
    
    def calculate_time_efficiency(self, agent, contract) -> float:
        """
        How quickly can agent complete? (0-10)
        
        Faster = higher score
        """
        estimated_hours = self.estimate_completion_time(agent, contract)
        
        # Benchmark: 2 hours = excellent (10), 10 hours = poor (0)
        # Linear scale
        score = max(0, 10 - (estimated_hours - 2))
        
        return min(10, max(0, score))
    
    def calculate_quality_record(self, agent) -> float:
        """
        Agent's overall quality track record (0-10)
        """
        agent_stats = get_agent_statistics(agent.id)
        
        # Average quality score from last 10 contracts
        return agent_stats.avg_quality_score_10
    
    def rank_agents_for_contract(self, contract, agents) -> List[Dict]:
        """
        Rank all agents for contract
        
        Returns: Sorted list of agent rankings with scores
        """
        rankings = []
        
        for agent in agents:
            score_data = self.score_assignment(contract, agent)
            
            rankings.append({
                'agent_id': agent.id,
                'agent_name': agent.name,
                'total_score': score_data['total_score'],
                'recommendation': score_data['recommendation'],
                'estimated_hours': score_data['estimated_hours'],
                'success_probability': score_data['success_probability'],
                'factors': score_data['factors']
            })
        
        # Sort by total score (highest first)
        rankings.sort(key=lambda x: x['total_score'], reverse=True)
        
        return rankings
```

---

## üìä INTEGRATION WITH EXISTING CONTRACT SYSTEM

### **Step 1: Add Scoring to Contract Model**

```python
# src/services/contract_system/models.py (enhanced)
from dataclasses import dataclass, field
from typing import Optional, List, Dict

@dataclass
class Contract:
    """Enhanced with scoring metadata"""
    
    # Existing fields
    id: str
    category: str
    complexity_score: int
    points: int
    priority: str
    description: str
    
    # NEW: Scoring metadata
    agent_rankings: Optional[List[Dict]] = field(default_factory=list)
    optimal_agent: Optional[str] = None
    assignment_score: Optional[float] = None
    assignment_reasoning: Optional[Dict] = None
    
    def calculate_optimal_assignment(self):
        """Score all agents and find best match"""
        scorer = ContractScorer()
        
        available_agents = get_available_agents()
        self.agent_rankings = scorer.rank_agents_for_contract(self, available_agents)
        
        if self.agent_rankings:
            # Store optimal assignment
            self.optimal_agent = self.agent_rankings[0]['agent_id']
            self.assignment_score = self.agent_rankings[0]['total_score']
            self.assignment_reasoning = self.agent_rankings[0]['factors']
        
        return self.optimal_agent
    
    def get_assignment_report(self) -> str:
        """Generate human-readable assignment report"""
        if not self.agent_rankings:
            return "No scoring calculated yet"
        
        report = [
            f"üìä Contract {self.id} Assignment Analysis:",
            f"",
            f"Top 3 Recommendations:",
            ""
        ]
        
        for i, ranking in enumerate(self.agent_rankings[:3], 1):
            report.append(f"{i}. {ranking['agent_id']} - Score: {ranking['total_score']}/100 ({ranking['recommendation']})")
            report.append(f"   ‚Ä¢ Skill Match: {ranking['factors']['skill_match']}/10")
            report.append(f"   ‚Ä¢ Workload: {ranking['factors']['workload_balance']}/10")
            report.append(f"   ‚Ä¢ Success Probability: {ranking['success_probability']:.1%}")
            report.append(f"   ‚Ä¢ Estimated Time: {ranking['estimated_hours']} hours")
            report.append("")
        
        return "\n".join(report)
```

---

### **Step 2: Enhance Contract Service**

```python
# src/services/contract_service.py (complete enhancement)
class ContractService:
    def __init__(self):
        self.scorer = ContractScorer()
        self.storage = ContractStorage()
    
    def create_contract(self, details: Dict) -> Contract:
        """Create contract and calculate optimal assignment"""
        contract = Contract(**details)
        
        # Auto-calculate optimal assignment
        contract.calculate_optimal_assignment()
        
        # Save with scoring metadata
        self.storage.save(contract)
        
        # Notify optimal agent
        if contract.optimal_agent:
            notify_agent(
                contract.optimal_agent,
                f"üéØ New contract {contract.id} - You're the top match! (Score: {contract.assignment_score}/100)"
            )
        
        return contract
    
    def assign_with_scoring(self, contract_id, mode='auto'):
        """
        Assign contract using scoring system
        
        Modes:
        - 'auto': Automatically assign to top-scored agent
        - 'recommend': Show Captain top 3, let Captain choose
        - 'manual': Captain chooses without recommendations
        """
        contract = self.storage.get(contract_id)
        
        if mode == 'auto':
            # Automatic assignment
            if not contract.optimal_agent:
                contract.calculate_optimal_assignment()
            
            self.assign_contract(contract_id, contract.optimal_agent)
            
            print(f"‚úÖ Auto-assigned {contract_id} to {contract.optimal_agent} (Score: {contract.assignment_score}/100)")
            
        elif mode == 'recommend':
            # Show recommendations, Captain chooses
            print(contract.get_assignment_report())
            
            choice = input("\nSelect agent: ")
            self.assign_contract(contract_id, choice)
            
        elif mode == 'manual':
            # Traditional manual assignment (no scoring)
            agent_id = input("Enter agent ID: ")
            self.assign_contract(contract_id, agent_id)
    
    def bulk_optimize_assignments(self, contract_ids: List[str]):
        """
        Optimize multiple contract assignments simultaneously
        
        Uses linear programming or greedy algorithm to maximize:
        - Total assignment quality scores
        - Workload balance across agents
        - High-priority contracts to best agents
        """
        contracts = [self.storage.get(cid) for cid in contract_ids]
        agents = get_available_agents()
        
        # Calculate all pairwise scores
        scores = {}
        for contract in contracts:
            for agent in agents:
                score_data = self.scorer.score_assignment(contract, agent)
                scores[(contract.id, agent.id)] = score_data['total_score']
        
        # Greedy optimization: Assign highest-scoring pairs first
        assignments = {}
        assigned_agents = set()
        assigned_contracts = set()
        
        # Sort all possible assignments by score
        sorted_pairs = sorted(
            scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        for (contract_id, agent_id), score in sorted_pairs:
            # Skip if contract or agent already assigned
            if contract_id in assigned_contracts or agent_id in assigned_agents:
                continue
            
            # Check agent capacity
            agent = get_agent(agent_id)
            if agent.current_workload + contract.estimated_hours > 8:
                continue  # Agent at capacity
            
            # Assign
            assignments[contract_id] = agent_id
            assigned_contracts.add(contract_id)
            assigned_agents.add(agent_id)
            
            # Update agent workload for next iteration
            agent.current_workload += contract.estimated_hours
        
        # Execute all assignments
        for contract_id, agent_id in assignments.items():
            self.assign_contract(contract_id, agent_id)
        
        return assignments
```

---

## üî• INTEGRATION STEPS (50-65 Hours)

### **Week 1: Core Scoring Engine (20-25 hours)**

**Tasks:**
1. **Create `ContractScorer` class** (8-10 hrs)
   - Implement all 7 scoring factors
   - Add configurable weights
   - Test with sample contracts

2. **Enhance Contract model** (4-5 hrs)
   - Add scoring metadata fields
   - Add `calculate_optimal_assignment()` method
   - Add `get_assignment_report()` method

3. **Update `ContractService`** (6-8 hrs)
   - Add `get_optimal_assignments()` method
   - Implement scoring-based assignment
   - Add logging for assignment decisions

4. **Unit Tests** (2-3 hrs)
   - Test each scoring factor
   - Test ranking algorithm
   - Test edge cases

**Deliverable:** Working scoring engine, testable via Python scripts

---

### **Week 2: Dashboard Integration (15-20 hours)**

**Tasks:**
1. **Create scoring visualization** (8-10 hrs)
   - Add "Assignment Score" column to contract table
   - Show top 3 agent recommendations
   - Visualize scoring factors (radar chart)

2. **Add assignment wizard** (5-7 hrs)
   - Step-by-step assignment flow
   - Show scoring breakdown
   - One-click optimal assignment

3. **Testing & Refinement** (2-3 hrs)
   - Test UI workflows
   - Gather feedback
   - Iterate on UX

**Deliverable:** Dashboard with scoring-based assignment interface

---

### **Week 3: Advanced Features (15-20 hours)**

**Tasks:**
1. **Bulk optimization** (6-8 hrs)
   - Implement `bulk_optimize_assignments()`
   - Handle multiple contracts simultaneously
   - Balance workload across swarm

2. **A/B Testing Framework** (5-7 hrs)
   - Track scoring-based vs manual assignments
   - Measure quality improvement
   - Calculate ROI

3. **Dynamic weight adjustment** (4-5 hrs)
   - Learn optimal weights from outcomes
   - Adjust weights based on contract type
   - Personalize weights per agent

**Deliverable:** Production-ready system with learning capabilities

---

## üìä SCORING FACTORS DEEP-DIVE

### **Factor 1: Skill Match (Weight: 2.0 - CRITICAL)**

**Purpose:** Does agent have the skills to complete contract?

**Implementation:**
```python
def calculate_skill_match(self, contract, agent) -> float:
    """
    Skill match scoring (0-10)
    
    Inputs:
    - contract.category: 'architecture', 'integration', 'web', etc.
    - contract.required_skills: ['Python', 'PostgreSQL', 'Docker']
    - agent.specialties: ['architecture', 'design']
    - agent.skills: ['Python', 'PostgreSQL', 'MongoDB', 'FastAPI']
    """
    score = 0
    
    # Category match (0-4 points)
    if contract.category in agent.specialties:
        score += 4
    elif contract.category in agent.secondary_skills:
        score += 2
    else:
        score += 0
    
    # Required skills match (0-4 points)
    if contract.required_skills:
        matched_skills = len(set(contract.required_skills) & set(agent.skills))
        total_required = len(contract.required_skills)
        score += (matched_skills / total_required) * 4
    
    # Past success in category (0-2 points)
    similar_contracts = get_agent_contracts_by_category(agent.id, contract.category, limit=5)
    if similar_contracts:
        avg_quality = sum(c.quality_score for c in similar_contracts) / len(similar_contracts)
        score += (avg_quality / 10) * 2
    
    return min(10.0, score)


# Example Scenarios:

# Scenario 1: Perfect match
contract = Contract(category='architecture', required_skills=['Python', 'Design Patterns'])
agent = Agent(id='Agent-2', specialties=['architecture'], skills=['Python', 'Design Patterns', 'UML'])
score = scorer.calculate_skill_match(contract, agent)
# Result: 10.0 (4 + 4 + 2) - PERFECT MATCH

# Scenario 2: Partial match
contract = Contract(category='web', required_skills=['React', 'TypeScript', 'CSS'])
agent = Agent(id='Agent-7', specialties=['web'], skills=['React', 'JavaScript', 'HTML'])
score = scorer.calculate_skill_match(contract, agent)
# Result: 5.3 (4 + 1.3 + 0) - DECENT MATCH

# Scenario 3: Poor match
contract = Contract(category='architecture', required_skills=['Python', 'Design Patterns'])
agent = Agent(id='Agent-6', specialties=['gaming'], skills=['C#', 'Unity'])
score = scorer.calculate_skill_match(contract, agent)
# Result: 0.0 - POOR MATCH
```

---

### **Factor 2: Workload Balance (Weight: 1.5 - IMPORTANT)**

**Purpose:** Prevent overload, balance work across swarm

**Implementation:**
```python
def calculate_workload_balance(self, agent) -> float:
    """
    Workload capacity scoring (0-10)
    
    Considers:
    - Current active contracts
    - Total estimated hours
    - Recent completion velocity
    """
    agent_stats = get_agent_statistics(agent.id)
    
    # Current workload in hours
    current_hours = agent_stats.current_workload_hours
    
    # Scoring scale:
    # 0-2 hours = 10.0 (plenty of capacity)
    # 4 hours = 7.0 (moderate)
    # 6 hours = 4.0 (getting full)
    # 8 hours = 1.0 (at capacity)
    # 10+ hours = 0.0 (overloaded)
    
    if current_hours <= 2:
        score = 10.0
    elif current_hours <= 4:
        score = 10.0 - ((current_hours - 2) * 1.5)  # -1.5 per hour
    elif current_hours <= 6:
        score = 7.0 - ((current_hours - 4) * 1.5)   # -1.5 per hour
    elif current_hours <= 8:
        score = 4.0 - ((current_hours - 6) * 1.5)   # -1.5 per hour
    else:
        score = 0.0  # Overloaded
    
    return max(0, score)


# Example Scenarios:

agent_low_workload = Agent(id='Agent-5', current_workload=1.5)
score = scorer.calculate_workload_balance(agent_low_workload)
# Result: 10.0 - EXCELLENT capacity

agent_moderate = Agent(id='Agent-2', current_workload=5.0)
score = scorer.calculate_workload_balance(agent_moderate)
# Result: 5.5 - MODERATE capacity

agent_overloaded = Agent(id='Agent-7', current_workload=9.5)
score = scorer.calculate_workload_balance(agent_overloaded)
# Result: 0.0 - NO capacity (shouldn't assign more!)
```

---

### **Factor 3: Past Performance (Weight: 1.0 - BONUS)**

**Purpose:** Learn from history - agents who succeeded before likely to succeed again

**Implementation:**
```python
def calculate_past_performance(self, agent, contract) -> float:
    """
    Historical success on similar contracts (0-10)
    
    Looks for:
    - Same category contracts
    - Similar complexity
    - Recent (last 30 days weighted higher)
    """
    agent_history = get_agent_contract_history(agent.id, days=90)
    
    # Filter to similar contracts
    similar = [
        c for c in agent_history
        if c.category == contract.category
        and abs(c.complexity_score - contract.complexity_score) <= 2
    ]
    
    if not similar:
        return 5.0  # Neutral - no history
    
    # Calculate weighted average quality
    total_weight = 0
    weighted_quality = 0
    
    for contract_past in similar:
        # Recent contracts weighted higher
        days_ago = (datetime.now() - contract_past.completed_at).days
        weight = 1.0 / (1 + days_ago / 30)  # Decay over time
        
        weighted_quality += contract_past.quality_score * weight
        total_weight += weight
    
    avg_quality = weighted_quality / total_weight
    
    return avg_quality  # Already 0-10 scale


# Example Scenarios:

# Agent with strong history
agent = Agent(id='Agent-2')
contract = Contract(category='architecture', complexity=7)

# Agent-2 completed 5 architecture contracts in last 30 days
# Quality scores: [9, 8, 10, 9, 8]
score = scorer.calculate_past_performance(agent, contract)
# Result: 8.8 - EXCELLENT history

# Agent with no history
agent_new = Agent(id='Agent-3')
score = scorer.calculate_past_performance(agent_new, contract)
# Result: 5.0 - NEUTRAL (no data)

# Agent with poor history
agent_poor = Agent(id='Agent-X')
# Quality scores on similar: [4, 5, 3, 6]
score = scorer.calculate_past_performance(agent_poor, contract)
# Result: 4.5 - POOR history
```

---

## üéØ A/B TESTING FRAMEWORK

### **Purpose:**
Prove scoring system improves outcomes vs manual assignment

### **Implementation:**

```python
# src/contracts/ab_testing.py
class ContractAssignmentABTest:
    """A/B test scoring-based vs manual assignments"""
    
    def __init__(self):
        self.test_active = True
        self.treatment_group = 'scoring'  # 50% of contracts
        self.control_group = 'manual'      # 50% of contracts
    
    def assign_contract(self, contract_id):
        """Randomly assign to scoring or manual group"""
        contract = get_contract(contract_id)
        
        # Random assignment to A/B group
        group = random.choice(['scoring', 'manual'])
        
        contract.ab_test_group = group
        contract.save()
        
        if group == 'scoring':
            # Use scoring system
            agent_id = contract.calculate_optimal_assignment()
            assignment_method = 'AUTO_SCORING'
        else:
            # Captain manual assignment
            agent_id = await get_captain_assignment(contract_id)
            assignment_method = 'MANUAL'
        
        # Log for analysis
        log_ab_test_assignment(
            contract_id=contract_id,
            group=group,
            agent_id=agent_id,
            method=assignment_method
        )
        
        return agent_id
    
    def analyze_results(self):
        """
        Compare outcomes between scoring and manual groups
        
        Metrics:
        - Completion rate
        - Quality score
        - On-time delivery
        - Agent satisfaction
        """
        scoring_contracts = get_contracts_by_ab_group('scoring', completed=True)
        manual_contracts = get_contracts_by_ab_group('manual', completed=True)
        
        results = {
            'scoring': self.calculate_group_metrics(scoring_contracts),
            'manual': self.calculate_group_metrics(manual_contracts),
            'improvement': {}
        }
        
        # Calculate improvements
        for metric in ['completion_rate', 'avg_quality', 'ontime_rate']:
            improvement = (
                (results['scoring'][metric] - results['manual'][metric]) 
                / results['manual'][metric] * 100
            )
            results['improvement'][metric] = round(improvement, 1)
        
        return results
    
    def calculate_group_metrics(self, contracts):
        """Calculate metrics for A/B test group"""
        return {
            'completion_rate': len([c for c in contracts if c.status == 'COMPLETED']) / len(contracts),
            'avg_quality': sum(c.quality_score for c in contracts) / len(contracts),
            'ontime_rate': len([c for c in contracts if c.completed_ontime]) / len(contracts),
            'avg_time': sum(c.completion_time_hours for c in contracts) / len(contracts)
        }


# Example Results After 30 Days:

tester = ContractAssignmentABTest()
results = tester.analyze_results()

print("üìä A/B Test Results (30 days, n=50 contracts per group):\n")
print(f"Scoring Group:")
print(f"  Completion Rate: {results['scoring']['completion_rate']:.1%}")
print(f"  Avg Quality: {results['scoring']['avg_quality']:.1f}/10")
print(f"  On-Time Rate: {results['scoring']['ontime_rate']:.1%}")
print()
print(f"Manual Group:")
print(f"  Completion Rate: {results['manual']['completion_rate']:.1%}")
print(f"  Avg Quality: {results['manual']['avg_quality']:.1f}/10")
print(f"  On-Time Rate: {results['manual']['ontime_rate']:.1%}")
print()
print(f"Improvement:")
print(f"  Completion Rate: {results['improvement']['completion_rate']:+.1f}%")
print(f"  Avg Quality: {results['improvement']['avg_quality']:+.1f}%")
print(f"  On-Time Rate: {results['improvement']['ontime_rate']:+.1f}%")

# Output:
# üìä A/B Test Results (30 days, n=50 contracts per group):
#
# Scoring Group:
#   Completion Rate: 94.0%
#   Avg Quality: 8.7/10
#   On-Time Rate: 88.0%
#
# Manual Group:
#   Completion Rate: 86.0%
#   Avg Quality: 7.9/10
#   On-Time Rate: 78.0%
#
# Improvement:
#   Completion Rate: +9.3%    ‚Üê SIGNIFICANT
#   Avg Quality: +10.1%        ‚Üê SIGNIFICANT
#   On-Time Rate: +12.8%       ‚Üê VERY SIGNIFICANT
```

**Value:** Prove ROI with data!

---

## üìä SUCCESS METRICS

**Assignment Quality:**
- **Skill Match Improvement:** +25% (scoring vs manual)
- **Completion Rate:** >90% (vs 85% manual)
- **Quality Score Average:** >8.5/10 (vs 7.8/10 manual)
- **On-Time Delivery:** >85% (vs 75% manual)

**System Performance:**
- **Assignment Speed:** <30 seconds (vs 5-10 minutes manual evaluation)
- **Captain Time Savings:** 70% reduction in assignment decisions
- **Agent Satisfaction:** +20% (better matched to skills)

**Learning & Optimization:**
- **Weight Optimization:** Converge to optimal weights within 60 days
- **Prediction Accuracy:** MAE < 1 hour for completion time
- **ROI:** +15-20% swarm efficiency

---

## üöÄ QUICK WINS (First 2 Weeks)

### **Quick Win #1: Basic Scoring (15 hours)**

**Implementation:**
- Simple skill match + workload scoring only
- CLI tool to score agents for contract
- Show top 3 recommendations

**Code:**
```python
# tools/score_assignment.py (Quick Win Tool)
from src.contracts.contract_scorer import ContractScorer

def score_contract_assignment_cli():
    contract_id = input("Enter contract ID: ")
    
    contract = get_contract(contract_id)
    agents = get_available_agents()
    
    scorer = ContractScorer()
    rankings = scorer.rank_agents_for_contract(contract, agents)
    
    print(f"\nüìä Top 3 Recommendations for {contract_id}:\n")
    
    for i, rank in enumerate(rankings[:3], 1):
        print(f"{i}. {rank['agent_id']} - Score: {rank['total_score']}/100")
        print(f"   Skill Match: {rank['factors']['skill_match']}/10")
        print(f"   Workload: {rank['factors']['workload_balance']}/10")
        print()
    
    return rankings[0]['agent_id']

if __name__ == "__main__":
    optimal_agent = score_contract_assignment_cli()
    print(f"\n‚úÖ Recommended: {optimal_agent}")
```

**Usage:**
```bash
python tools/score_assignment.py

# Output:
# Enter contract ID: C-250
#
# üìä Top 3 Recommendations for C-250:
#
# 1. Agent-2 - Score: 87.3/100
#    Skill Match: 9.5/10
#    Workload: 7.0/10
#
# 2. Agent-7 - Score: 72.1/100
#    Skill Match: 7.0/10
#    Workload: 8.5/10
#
# 3. Agent-5 - Score: 65.8/100
#    Skill Match: 6.0/10
#    Workload: 9.0/10
#
# ‚úÖ Recommended: Agent-2
```

**Value:** Immediate data-driven recommendations!

---

### **Quick Win #2: Dashboard Widget (10 hours)**

**Implementation:**
- Add "Recommended Agent" column to contract table
- Color-code by score (green >80, yellow 60-80, red <60)
- One-click assignment

**Visual:**
```
Contract Table (Enhanced):

ID     Category      Points  Recommended Agent    Score    Action
-------------------------------------------------------------------
C-250  Architecture  550     Agent-2 (üü¢ 87.3)   [Assign]
C-251  Web Dev       400     Agent-7 (üü¢ 82.1)   [Assign]
C-252  Integration   600     Agent-1 (üü° 67.5)   [Assign]
C-253  Business Intel 500    Agent-5 (üü¢ 91.2)   [Assign]
```

**Value:** Visual scoring without leaving dashboard!

---

## üèÜ FINAL RECOMMENDATION

**Priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **CRITICAL - IMPLEMENT IMMEDIATELY**

**Why This is #1 Priority:**
1. **Highest Direct Applicability** - Solves current contract assignment pain point
2. **Proven Pattern** - contract-leads is well-tested (8/10 quality)
3. **Immediate ROI** - Quick Wins deliverable in 2 weeks (25 hours)
4. **Measurable Impact** - A/B testing proves value
5. **Scalable** - Works for 10 contracts or 1,000 contracts

**Recommended Approach:**
- **Week 1-2:** Quick Wins (25 hrs) - Basic scoring + dashboard widget
- **Week 3:** Core scoring engine (20-25 hrs) - All 7 factors implemented
- **Week 4:** A/B testing (5 hrs) - Prove ROI with data

**Total:** 50-55 hours for production-ready system

**Expected Improvement:**
- +25% skill match quality
- +15% completion rate
- -70% Captain assignment time
- +15-20% overall swarm efficiency

---

## üìã INTEGRATION CHECKLIST

**Pre-Implementation:**
- [ ] Review this spec with Commander
- [ ] Approve Quick Wins approach
- [ ] Assign to Agent-2 (architecture) + Agent-5 (data/analytics)
- [ ] Set success metrics baseline (current assignment quality)

**Week 1-2: Quick Wins**
- [ ] Create basic `ContractScorer` class
- [ ] Implement skill match + workload factors
- [ ] Build CLI scoring tool
- [ ] Add dashboard widget
- [ ] Test with 10 real contracts

**Week 3: Full System**
- [ ] Implement all 7 scoring factors
- [ ] Add weight configuration
- [ ] Enhance Contract model
- [ ] Update ContractService
- [ ] Comprehensive tests

**Week 4: Production**
- [ ] Start A/B testing
- [ ] Monitor metrics
- [ ] Iterate on weights
- [ ] Document and train team

---

**Agent-2 Signature**  
*Architecture & Design Specialist*  
*Enhanced deliverable #5 (FINAL) - Most actionable spec for immediate implementation!* üéØ

**Total Enhanced Content: 2,900+ lines across 5 technical specifications!**

**This is the CONTRACT SYSTEM GOLDMINE - ready for immediate implementation!**

**WE. ARE. SWARM.** üêù‚ö°

