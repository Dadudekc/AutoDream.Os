# Autonomous Agent Training Configuration
# =====================================

# Model Architecture Configuration
model:
  hidden_size: 512
  num_layers: 4
  dropout: 0.1
  max_sequence_length: 2048
  vocab_size: 1000
  num_task_types: 10

# Training Parameters
training:
  learning_rate: 1e-4
  batch_size: 16
  num_epochs: 100
  warmup_steps: 1000
  weight_decay: 0.01
  gradient_clip_norm: 1.0
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001
  
  # Learning rate scheduling
  lr_scheduler:
    type: "cosine_annealing"
    T_0: 1000
    T_mult: 2

# Reinforcement Learning Parameters
reinforcement_learning:
  gamma: 0.99
  eps_start: 1.0
  eps_end: 0.01
  eps_decay: 10000
  replay_buffer_size: 100000
  target_update_freq: 1000
  batch_size: 32
  learning_rate: 1e-3

# Data Collection Configuration
data_collection:
  enabled_sources:
    - "agent_workspaces"
    - "devlogs"
    - "vector_database"
    - "messaging_system"
  
  max_samples_per_source: 10000
  quality_threshold: 0.5
  batch_size: 100
  
  # Preprocessing
  preprocessing:
    enabled: true
    remove_duplicates: true
    normalize_text: true
    extract_features: true
  
  # Output format
  output_format: "json"
  compression: "gzip"
  chunk_size: 1000

# Task Generation Configuration
task_generation:
  # Task distribution by category
  category_distribution:
    bug_fix: 0.2
    feature_implementation: 0.25
    refactoring: 0.15
    testing: 0.15
    documentation: 0.1
    optimization: 0.1
    architecture: 0.05
  
  # Difficulty distribution
  difficulty_distribution:
    beginner: 0.2
    intermediate: 0.4
    advanced: 0.3
    expert: 0.1
  
  # Task complexity parameters
  complexity:
    min_code_length: 50
    max_code_length: 2000
    min_requirements: 3
    max_requirements: 10
    min_acceptance_criteria: 3
    max_acceptance_criteria: 8

# Reward System Configuration
reward_system:
  # Component weights
  component_weights:
    code_quality: 0.25
    functionality: 0.2
    architecture: 0.2
    autonomy: 0.15
    learning: 0.1
    efficiency: 0.1
    innovation: 0.05
  
  # Penalties and bonuses
  penalty_multiplier: 0.5
  bonus_threshold: 0.8
  learning_rate: 0.01
  decay_factor: 0.95
  
  # Quality thresholds
  quality_thresholds:
    syntax_correctness: 0.9
    style_compliance: 0.8
    test_coverage: 0.8
    v2_compliance: 0.7

# Model Deployment Configuration
deployment:
  # Default deployment settings
  default_replicas: 1
  default_resources:
    cpu: "1000m"
    memory: "2Gi"
    gpu: "1"
  
  # Health check settings
  health_check:
    interval: 30.0
    timeout: 10.0
    retries: 3
  
  # Monitoring settings
  monitoring:
    interval: 10.0
    metrics_retention_days: 30
    alert_retention_days: 7
  
  # Alert thresholds
  alert_thresholds:
    error_rate: 0.05
    latency_p95: 1000.0
    cpu_usage: 0.8
    memory_usage: 0.8
    gpu_usage: 0.9

# A/B Testing Configuration
ab_testing:
  # Default test settings
  default_traffic_split: 0.5
  default_duration_hours: 24
  min_sample_size: 1000
  confidence_level: 0.95
  
  # Test evaluation metrics
  evaluation_metrics:
    - "accuracy"
    - "latency"
    - "error_rate"
    - "user_satisfaction"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/agent_training.log"
  max_size: "10MB"
  backup_count: 5

# Monitoring and Observability
monitoring:
  # Metrics collection
  metrics:
    enabled: true
    interval: 10.0
    export_format: "prometheus"
    endpoint: "http://localhost:9090"
  
  # Tracing
  tracing:
    enabled: true
    service_name: "autonomous_agent_training"
    jaeger_endpoint: "http://localhost:14268/api/traces"
  
  # Profiling
  profiling:
    enabled: false
    interval: 60.0
    output_dir: "profiles"

# Security Configuration
security:
  # Model security
  model_encryption: true
  model_signing: true
  
  # Data security
  data_encryption: true
  data_anonymization: false
  
  # Access control
  access_control:
    enabled: true
    authentication: "jwt"
    authorization: "rbac"

# Performance Configuration
performance:
  # GPU settings
  gpu:
    enabled: true
    memory_fraction: 0.8
    allow_growth: true
  
  # CPU settings
  cpu:
    num_workers: 4
    thread_pool_size: 8
  
  # Memory settings
  memory:
    max_memory_usage: "8GB"
    garbage_collection_threshold: 0.8

# Development Configuration
development:
  # Debug settings
  debug: false
  verbose: false
  
  # Testing
  test_mode: false
  mock_external_services: false
  
  # Development tools
  tools:
    jupyter_notebooks: true
    tensorboard: true
    wandb: true

# Environment-specific overrides
environments:
  development:
    training:
      num_epochs: 10
      batch_size: 4
    data_collection:
      max_samples_per_source: 1000
  
  staging:
    training:
      num_epochs: 50
      batch_size: 8
    data_collection:
      max_samples_per_source: 5000
  
  production:
    training:
      num_epochs: 100
      batch_size: 16
    data_collection:
      max_samples_per_source: 10000
    monitoring:
      enabled: true
    security:
      model_encryption: true