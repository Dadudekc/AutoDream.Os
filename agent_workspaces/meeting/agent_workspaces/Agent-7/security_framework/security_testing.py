"""
ðŸ”’ SECURITY TESTING FRAMEWORK - SECURITY FRAMEWORK COMPONENT
Agent-7 - Security & Quality Assurance Manager

Security testing framework and validation for comprehensive security assessment.
Follows V2 coding standards: â‰¤300 lines per module.
"""

import unittest
import json
import os
from typing import Dict, List, Any, Optional, Callable
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime

from .bandit_scanner import BanditSecurityScanner
from .safety_checker import SafetyDependencyChecker
from .secure_coding_guidelines import SecureCodingGuidelines


@dataclass
class SecurityTestResult:
    """Result of a security test."""
    test_name: str
    test_category: str
    status: str  # PASS, FAIL, ERROR, SKIPPED
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    description: str
    details: Dict[str, Any]
    timestamp: str
    execution_time: float


class SecurityTestingFramework:
    """Comprehensive security testing framework for applications."""
    
    def __init__(self):
        """Initialize security testing framework."""
        self.bandit_scanner = BanditSecurityScanner()
        self.safety_checker = SafetyDependencyChecker()
        self.secure_coding_checker = SecureCodingGuidelines()
        
        self.test_categories = {
            "code_analysis": "Static code analysis for security vulnerabilities",
            "dependency_check": "Dependency vulnerability assessment",
            "secure_coding": "Secure coding practices compliance",
            "penetration_testing": "Basic penetration testing scenarios",
            "configuration_audit": "Security configuration validation"
        }
        
        self.test_results = []
        self.overall_security_score = 100.0
    
    def run_comprehensive_security_test(self, target_directory: str) -> Dict[str, Any]:
        """
        Run comprehensive security testing suite.
        
        Args:
            target_directory: Path to test for security vulnerabilities
            
        Returns:
            dict: Comprehensive security test results
        """
        test_start_time = datetime.now()
        
        comprehensive_results = {
            "test_session_id": f"SECURITY_TEST_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "target_directory": target_directory,
            "test_start_time": test_start_time.isoformat(),
            "test_categories": list(self.test_categories.keys()),
            "overall_security_score": 100.0,
            "test_results": {},
            "summary": {},
            "recommendations": []
        }
        
        try:
            # Run all security tests
            comprehensive_results["test_results"] = {
                "code_analysis": self._run_code_analysis_test(target_directory),
                "dependency_check": self._run_dependency_check_test(target_directory),
                "secure_coding": self._run_secure_coding_test(target_directory),
                "penetration_testing": self._run_penetration_testing(target_directory),
                "configuration_audit": self._run_configuration_audit(target_directory)
            }
            
            # Calculate overall security score
            comprehensive_results["overall_security_score"] = self._calculate_overall_score(
                comprehensive_results["test_results"]
            )
            
            # Generate summary and recommendations
            comprehensive_results["summary"] = self._generate_test_summary(
                comprehensive_results["test_results"]
            )
            comprehensive_results["recommendations"] = self._generate_comprehensive_recommendations(
                comprehensive_results["test_results"]
            )
            
            # Calculate execution time
            test_end_time = datetime.now()
            execution_time = (test_end_time - test_start_time).total_seconds()
            comprehensive_results["execution_time"] = execution_time
            comprehensive_results["test_end_time"] = test_end_time.isoformat()
            
        except Exception as e:
            comprehensive_results["error"] = f"Comprehensive test error: {str(e)}"
            comprehensive_results["overall_security_score"] = 0.0
        
        return comprehensive_results
    
    def _run_code_analysis_test(self, target_directory: str) -> Dict[str, Any]:
        """Run Bandit code analysis security test."""
        test_result = SecurityTestResult(
            test_name="Code Security Analysis",
            test_category="code_analysis",
            status="PENDING",
            severity="MEDIUM",
            description="Static code analysis using Bandit security linter",
            details={},
            timestamp=datetime.now().isoformat(),
            execution_time=0.0
        )
        
        try:
            start_time = datetime.now()
            
            # Run Bandit scan
            scan_results = self.bandit_scanner.scan_directory(target_directory)
            
            # Calculate execution time
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            # Determine test status
            if scan_results.get("scan_status") == "COMPLETED":
                if scan_results.get("total_issues", 0) == 0:
                    test_result.status = "PASS"
                    test_result.severity = "LOW"
                else:
                    test_result.status = "FAIL"
                    high_issues = scan_results.get("issues_by_severity", {}).get("HIGH", 0)
                    critical_issues = scan_results.get("issues_by_severity", {}).get("CRITICAL", 0)
                    if critical_issues > 0:
                        test_result.severity = "CRITICAL"
                    elif high_issues > 0:
                        test_result.severity = "HIGH"
                    else:
                        test_result.severity = "MEDIUM"
            else:
                test_result.status = "ERROR"
                test_result.severity = "HIGH"
            
            test_result.details = scan_results
            test_result.execution_time = execution_time
            
        except Exception as e:
            test_result.status = "ERROR"
            test_result.severity = "HIGH"
            test_result.details = {"error": str(e)}
        
        return self._test_result_to_dict(test_result)
    
    def _run_dependency_check_test(self, target_directory: str) -> Dict[str, Any]:
        """Run Safety dependency vulnerability check test."""
        test_result = SecurityTestResult(
            test_name="Dependency Vulnerability Check",
            test_category="dependency_check",
            status="PENDING",
            severity="MEDIUM",
            description="Dependency vulnerability assessment using Safety",
            details={},
            timestamp=datetime.now().isoformat(),
            execution_time=0.0
        )
        
        try:
            start_time = datetime.now()
            
            # Look for requirements.txt file
            requirements_file = self._find_requirements_file(target_directory)
            
            # Run Safety check
            check_results = self.safety_checker.check_dependencies(requirements_file)
            
            # Calculate execution time
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            # Determine test status
            if check_results.get("check_status") == "COMPLETED":
                if check_results.get("total_vulnerabilities", 0) == 0:
                    test_result.status = "PASS"
                    test_result.severity = "LOW"
                else:
                    test_result.status = "FAIL"
                    critical_vulns = check_results.get("vulnerabilities_by_severity", {}).get("CRITICAL", 0)
                    high_vulns = check_results.get("vulnerabilities_by_severity", {}).get("HIGH", 0)
                    if critical_vulns > 0:
                        test_result.severity = "CRITICAL"
                    elif high_vulns > 0:
                        test_result.severity = "HIGH"
                    else:
                        test_result.severity = "MEDIUM"
            else:
                test_result.status = "ERROR"
                test_result.severity = "HIGH"
            
            test_result.details = check_results
            test_result.execution_time = execution_time
            
        except Exception as e:
            test_result.status = "ERROR"
            test_result.severity = "HIGH"
            test_result.details = {"error": str(e)}
        
        return self._test_result_to_dict(test_result)
    
    def _run_secure_coding_test(self, target_directory: str) -> Dict[str, Any]:
        """Run secure coding guidelines compliance test."""
        test_result = SecurityTestResult(
            test_name="Secure Coding Compliance",
            test_category="secure_coding",
            status="PENDING",
            severity="MEDIUM",
            description="Secure coding practices compliance check",
            details={},
            timestamp=datetime.now().isoformat(),
            execution_time=0.0
        )
        
        try:
            start_time = datetime.now()
            
            # Run secure coding analysis
            analysis_results = self.secure_coding_checker.analyze_code_security(target_directory)
            
            # Calculate execution time
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            # Determine test status
            if analysis_results.get("compliance_status") == "COMPLETED":
                if analysis_results.get("total_violations", 0) == 0:
                    test_result.status = "PASS"
                    test_result.severity = "LOW"
                else:
                    test_result.status = "FAIL"
                    critical_violations = analysis_results.get("violations_by_severity", {}).get("CRITICAL", 0)
                    high_violations = analysis_results.get("violations_by_severity", {}).get("HIGH", 0)
                    if critical_violations > 0:
                        test_result.severity = "CRITICAL"
                    elif high_violations > 0:
                        test_result.severity = "HIGH"
                    else:
                        test_result.severity = "MEDIUM"
            else:
                test_result.status = "ERROR"
                test_result.severity = "HIGH"
            
            test_result.details = analysis_results
            test_result.execution_time = execution_time
            
        except Exception as e:
            test_result.status = "ERROR"
            test_result.severity = "HIGH"
            test_result.details = {"error": str(e)}
        
        return self._test_result_to_dict(test_result)
    
    def _run_penetration_testing(self, target_directory: str) -> Dict[str, Any]:
        """Run basic penetration testing scenarios."""
        test_result = SecurityTestResult(
            test_name="Basic Penetration Testing",
            test_category="penetration_testing",
            status="SKIPPED",
            severity="MEDIUM",
            description="Basic penetration testing scenarios (placeholder)",
            details={},
            timestamp=datetime.now().isoformat(),
            execution_time=0.0
        )
        
        # Placeholder for penetration testing
        test_result.details = {
            "note": "Penetration testing requires specialized tools and environment setup",
            "recommendations": [
                "Use tools like OWASP ZAP for web application testing",
                "Implement automated penetration testing in staging environments",
                "Conduct regular manual penetration testing by security professionals"
            ]
        }
        
        return self._test_result_to_dict(test_result)
    
    def _run_configuration_audit(self, target_directory: str) -> Dict[str, Any]:
        """Run security configuration audit."""
        test_result = SecurityTestResult(
            test_name="Security Configuration Audit",
            test_category="configuration_audit",
            status="PENDING",
            severity="MEDIUM",
            description="Security configuration validation and audit",
            details={},
            timestamp=datetime.now().isoformat(),
            execution_time=0.0
        )
        
        try:
            start_time = datetime.now()
            
            # Basic configuration audit
            config_audit = self._audit_security_configuration(target_directory)
            
            # Calculate execution time
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            # Determine test status
            if config_audit.get("total_issues", 0) == 0:
                test_result.status = "PASS"
                test_result.severity = "LOW"
            else:
                test_result.status = "FAIL"
                test_result.severity = "MEDIUM"
            
            test_result.details = config_audit
            test_result.execution_time = execution_time
            
        except Exception as e:
            test_result.status = "ERROR"
            test_result.severity = "HIGH"
            test_result.details = {"error": str(e)}
        
        return self._test_result_to_dict(test_result)
    
    def _audit_security_configuration(self, target_directory: str) -> Dict[str, Any]:
        """Audit security configuration files and settings."""
        config_audit = {
            "total_issues": 0,
            "issues": [],
            "config_files_found": [],
            "security_settings": {}
        }
        
        target_path = Path(target_directory)
        
        # Check for common configuration files
        config_patterns = [
            "*.conf", "*.config", "*.ini", "*.yaml", "*.yml", "*.json",
            "requirements.txt", "setup.py", "pyproject.toml"
        ]
        
        for pattern in config_patterns:
            for config_file in target_path.rglob(pattern):
                if config_file.is_file():
                    config_audit["config_files_found"].append(str(config_file))
                    
                    # Basic security checks for common files
                    if config_file.name == "requirements.txt":
                        config_audit["security_settings"]["dependencies"] = "requirements.txt found"
                    elif config_file.name == "setup.py":
                        config_audit["security_settings"]["setup"] = "setup.py found"
        
        # Check for security-related files
        security_files = [
            ".env", ".env.local", ".env.production",
            "secrets.json", "config.json", "settings.py"
        ]
        
        for sec_file in security_files:
            sec_path = target_path / sec_file
            if sec_path.exists():
                config_audit["security_settings"][sec_file] = f"Security file {sec_file} found"
                if sec_file.startswith(".env"):
                    config_audit["issues"].append(f"Environment file {sec_file} should not be committed to version control")
                    config_audit["total_issues"] += 1
        
        return config_audit
    
    def _find_requirements_file(self, target_directory: str) -> Optional[str]:
        """Find requirements.txt file in target directory."""
        target_path = Path(target_directory)
        
        # Look for common requirements file names
        requirements_files = [
            "requirements.txt",
            "requirements-dev.txt",
            "requirements-prod.txt",
            "pyproject.toml"
        ]
        
        for req_file in requirements_files:
            req_path = target_path / req_file
            if req_path.exists():
                return str(req_path)
        
        return None
    
    def _calculate_overall_score(self, test_results: Dict[str, Any]) -> float:
        """Calculate overall security score from all test results."""
        if not test_results:
            return 0.0
        
        total_score = 0.0
        valid_tests = 0
        
        for category, result in test_results.items():
            if result.get("status") == "PASS":
                total_score += 100.0
                valid_tests += 1
            elif result.get("status") == "FAIL":
                # Calculate score based on severity
                severity = result.get("severity", "MEDIUM")
                if severity == "CRITICAL":
                    total_score += 0.0
                elif severity == "HIGH":
                    total_score += 25.0
                elif severity == "MEDIUM":
                    total_score += 50.0
                else:
                    total_score += 75.0
                valid_tests += 1
            elif result.get("status") == "SKIPPED":
                total_score += 50.0  # Neutral score for skipped tests
                valid_tests += 1
        
        if valid_tests == 0:
            return 0.0
        
        return round(total_score / valid_tests, 2)
    
    def _generate_test_summary(self, test_results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate summary of all test results."""
        summary = {
            "total_tests": len(test_results),
            "passed_tests": 0,
            "failed_tests": 0,
            "error_tests": 0,
            "skipped_tests": 0,
            "critical_issues": 0,
            "high_issues": 0,
            "medium_issues": 0,
            "low_issues": 0
        }
        
        for category, result in test_results.items():
            status = result.get("status", "UNKNOWN")
            severity = result.get("severity", "LOW")
            
            if status == "PASS":
                summary["passed_tests"] += 1
            elif status == "FAIL":
                summary["failed_tests"] += 1
            elif status == "ERROR":
                summary["error_tests"] += 1
            elif status == "SKIPPED":
                summary["skipped_tests"] += 1
            
            # Count issues by severity
            if severity == "CRITICAL":
                summary["critical_issues"] += 1
            elif severity == "HIGH":
                summary["high_issues"] += 1
            elif severity == "MEDIUM":
                summary["medium_issues"] += 1
            else:
                summary["low_issues"] += 1
        
        return summary
    
    def _generate_comprehensive_recommendations(self, test_results: Dict[str, Any]) -> List[str]:
        """Generate comprehensive recommendations based on all test results."""
        recommendations = []
        
        # Analyze overall test results
        total_tests = len(test_results)
        failed_tests = sum(1 for r in test_results.values() if r.get("status") == "FAIL")
        error_tests = sum(1 for r in test_results.values() if r.get("status") == "ERROR")
        
        if failed_tests > 0:
            recommendations.append(f"Address {failed_tests} failed security tests")
        
        if error_tests > 0:
            recommendations.append(f"Resolve {error_tests} test execution errors")
        
        # Specific recommendations based on test categories
        for category, result in test_results.items():
            if result.get("status") == "FAIL":
                if category == "code_analysis":
                    recommendations.append("Fix code security vulnerabilities identified by Bandit")
                elif category == "dependency_check":
                    recommendations.append("Update vulnerable dependencies identified by Safety")
                elif category == "secure_coding":
                    recommendations.append("Implement secure coding practices and fix violations")
                elif category == "configuration_audit":
                    recommendations.append("Review and secure configuration files")
        
        # General recommendations
        if failed_tests == 0 and error_tests == 0:
            recommendations.append("All security tests passed - maintain current security practices")
        
        recommendations.append("Implement automated security testing in CI/CD pipeline")
        recommendations.append("Conduct regular security assessments and penetration testing")
        recommendations.append("Provide ongoing security training for development teams")
        
        return recommendations
    
    def _test_result_to_dict(self, test_result: SecurityTestResult) -> Dict[str, Any]:
        """Convert SecurityTestResult to dictionary for JSON serialization."""
        return {
            "test_name": test_result.test_name,
            "test_category": test_result.test_category,
            "status": test_result.status,
            "severity": test_result.severity,
            "description": test_result.description,
            "details": test_result.details,
            "timestamp": test_result.timestamp,
            "execution_time": test_result.execution_time
        }
    
    def generate_security_test_report(self, test_results: Dict[str, Any], output_path: str) -> bool:
        """
        Generate comprehensive security testing report.
        
        Args:
            test_results: Results from comprehensive security testing
            output_path: Path to save the report
            
        Returns:
            bool: True if report generation successful
        """
        try:
            report_content = f"""# Comprehensive Security Testing Report

## Executive Summary
- **Test Session ID**: {test_results.get('test_session_id', 'Unknown')}
- **Target Directory**: {test_results.get('target_directory', 'Unknown')}
- **Overall Security Score**: {test_results.get('overall_security_score', 0):.1f}/100
- **Test Start Time**: {test_results.get('test_start_time', 'Unknown')}
- **Execution Time**: {test_results.get('execution_time', 0):.2f} seconds

## Test Summary
{chr(10).join(f"- **{key.replace('_', ' ').title()}**: {value}" for key, value in test_results.get('summary', {}).items())}

## Test Results by Category
{chr(10).join(f"### {category.replace('_', ' ').title()}\n- **Test Name**: {result.get('test_name', 'Unknown')}\n- **Status**: {result.get('status', 'Unknown')}\n- **Severity**: {result.get('severity', 'Unknown')}\n- **Execution Time**: {result.get('execution_time', 0):.2f}s\n- **Description**: {result.get('description', 'No description')}\n" for category, result in test_results.get('test_results', {}).items())}

## Recommendations
{chr(10).join(f"- {rec}" for rec in test_results.get('recommendations', []))}

## Next Steps
1. Address failed security tests immediately
2. Implement automated security testing
3. Conduct regular security assessments
4. Provide security training for teams
5. Establish security monitoring and alerting
"""
            
            with open(output_path, 'w') as f:
                f.write(report_content)
            
            return True
            
        except Exception as e:
            print(f"Error generating security test report: {e}")
            return False
